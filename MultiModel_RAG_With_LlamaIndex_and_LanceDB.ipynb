{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddff396",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-lancedb\n",
    "%pip install llama-index-multi-modal-11ms-openai\n",
    "%pip install llama-index-embeddings-clip I\n",
    "%pip install git+https://github.con/openai/CLIP.git\n",
    "%pip install llama-index-readers-file\n",
    "%pip install llama_index\n",
    "%pip install -U openai-whisper \n",
    "%pip install lancedb\n",
    "%pip install moviepy\n",
    "%pip install pytube\n",
    "%pip install pydub\n",
    "%pip install SpeechRecognition\n",
    "%pip install ffmpeg-python\n",
    "%pip install soundfile\n",
    "%pip install torchtorchvision\n",
    "%pip install matpotlib scikit-image\n",
    "%pip install ftfy regex tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0abce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from pathlib import Path\n",
    "import speech_recognition as sr\n",
    "from pytube import YouTube\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pytube import YouTube\n",
    "from moviepy.editor import VideoFileClip\n",
    "from google.colab import userdata\n",
    "from llama_index_core.indices import MultiModalVectorStoreIndex\n",
    "from llama_index.core import SimpelDirectroyReader, StorageContext\n",
    "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "from llama_index.core.schema import ImageNode\n",
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_TOKEN = userdata.get(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_TOKEN\"] = OPENAI_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ef411",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://youtu.be/3dhcmeOTZ_Q\"\n",
    "output_video_path = \"/content/video_data/\"\n",
    "\n",
    "# from video, collecting images, audio, text\n",
    "!mkdir mixed_data\n",
    "output_folder = \"/content/mixed_data/\"\n",
    "output_audio_path = \"/content/mixed_data/output_audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83cd4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = output_video_path + \"input_vid.mp4\"\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea07190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(url, output_path):\n",
    "    yt = YouTube(url)\n",
    "    metadata = {\"Author\": yt.author, \"Title\": yt.title, \"Views\": yt.views}\n",
    "    yt.streams.get_highest_reasolution().download(\n",
    "        output_path = output_path, filename=\"input_vid.mp4\"\n",
    "    )\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_image(video_path, output_folder):\n",
    "    clip = VideoFileClip(video_path)\n",
    "    clip.write_images_sequence(\n",
    "        os.path.join(output_folder, \"frame%04d.png\"), fps=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c81ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_audio(video_path, output_audio_path):\n",
    "    clip = VideoFileClip(video_path)\n",
    "    audio = clip.audio(\n",
    "        audio.write_audiofile(output_audio_path)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_text(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio = sr.AudioFile(audio_path)\n",
    "\n",
    "    with audio as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "        try:\n",
    "            # Recognize the speech\n",
    "            text = recognizer.recognize_whisper(audio_data)\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Speech recognition could not understand the audio.\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = download_video(video_url, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_to_image(file_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_to_audio(file_path, output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54d65f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = audio_to_text(output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fbd36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_folder + \"output_text.txt\", \"w\") as file:\n",
    "    file.write(text_data)\n",
    "    print(\"Text data saved to file\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(output_audio_path)\n",
    "print(\"Audio file removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a0427",
   "metadata": {},
   "source": [
    "Process video\n",
    "image\n",
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762df28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_store = LanceDBVectorStore(uri=\"lancedb\", table_name=\"text_collection\")\n",
    "image_store = LanceDBVectorStore(uri=\"lancedb\", table_name=\"image_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2164e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext(vector_store=text_store, image_store=image_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpelDirectroyReader(output_folder).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = MultiModalVectorStoreIndex(documents, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_engine = index.as_retriever(similarity_top_k=1, image_similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9752654",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_tmpl_str = (\n",
    "    \"\"\" Based on the provided information, including relevant images and retrieved context from the video, \\\n",
    "    accurately and precisely answer the query withoug any additional prior knowledge.\\n\"\"\"\n",
    "\n",
    "    \"--------------------------\\n\"\n",
    "    \"Context: {context}\\n\"\n",
    "    \"Metadata for video: {metadat}\\n\"\n",
    "\n",
    "    \"---------------------------\\n\"\n",
    "    \"Query: {query}\\n\"\n",
    "    \"Answer: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f0d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(retriever_engine, query_str):\n",
    "    retriever_result = retriever_engine.retriever(query_str)\n",
    "\n",
    "    retriever_image = []\n",
    "    retriever_text = []\n",
    "    for res_node in retriever_result:\n",
    "        if isinstance(res_node.node, ImageNode):\n",
    "            retriever_image.append(res_node, source_length=200)\n",
    "\n",
    "        else:\n",
    "            display_source_node(res_node, source_length=200)\n",
    "            retriever_text.append(res_node.text)\n",
    "\n",
    "    return retriever_image, retriever_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b92001",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \" What is linear regression? explain it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8bfd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "img , text = retrieve(retriever_engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images_path):\n",
    "    images_shown = 0\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    for img_path in images_path:\n",
    "        if os.path.isfile(img_path):\n",
    "            image = Image.open(img_path)\n",
    "\n",
    "            plt.subplot(2, 1, images_shown + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            images_shown += 1\n",
    "            if images_shown >= 5:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4dcfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_mm_llm = OpenAIMultiModal(model=\"gpt-4-vision-preview\", api_key=OPENAI_API_TOKEN, max_new_tokens=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64449103",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_str = \"\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3fe835",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_documents = SimpelDirectroyReader(input_files=img).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5154dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_str = json.dump(metadata) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c920633d",
   "metadata": {},
   "source": [
    "Even without context, the model can generate texts also and answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f826290",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_tmpl_str_2 = (\n",
    "    \"\"\" Based on the provided information, including relevant images and retrieved context from the video, \\\n",
    "    accurately and precisely answer the query withoug any additional prior knowledge.\\n\"\"\"\n",
    "\n",
    "    \"--------------------------\\n\"\n",
    "    \"Context: {context_str}\\n\"\n",
    "    \"Metadata for video: {metadat_str}\\n\"\n",
    "\n",
    "    \"---------------------------\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = openai_mm_llm.complete(\n",
    "    prompt = qa_tmpl_str_2.format(\n",
    "        query_str = query_str, metadata_str = metadata_str, context_str=context_str\n",
    "    ),\n",
    "    image_documents=image_documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(result.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
