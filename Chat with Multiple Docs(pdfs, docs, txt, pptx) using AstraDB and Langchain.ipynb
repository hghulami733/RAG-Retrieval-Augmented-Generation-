{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30cf990",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain unstructured openai Cython tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade langchain-astradb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3068a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain-openai datasets pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e862c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install unstructured-pytesseract tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"unstructured[pptx]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74454dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pdf2image pdfminer.six unstructured[pdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from datasets import (\n",
    "    load_dataset,\n",
    ")\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from google.colab import userdata\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_community.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae36d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb351d",
   "metadata": {},
   "source": [
    "Using Unstructured for loading Multiple pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c699c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/content/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82607f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder_path = f\"{root_dir}/docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ccacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(pdf_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5946800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the pdf file/files\n",
    "loaders = [UnstructuredPDFLoader(os.path.join(pdf_folder_path), fn) for fn in os.listdir(pdf_folder_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a456da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator().from_loaders(loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.query(\"What is the tokenization in RAG?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.query_with_sources(\"What is the tokenization in RAG?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98f8832",
   "metadata": {},
   "source": [
    "Pypdf loader with Multiple Pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7272479",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASTRA_DB_API_ENDPOINT = \"ASTRA_DB_API_ENDPOINT\"\n",
    "ASTRA_DB_APPLICATION_TOKEN = \"ASTRA_DB_APPLICATION_TOKEN\"\n",
    "ASTRA_DB_KEYSPACE = \"ASTRA_DB_KEYSPACE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = os.listdir(pdf_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4bdcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PyPDFLoader(\"/content/data/MachineTranslationwithAttention.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79fa44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.load_and_split(text_splitter=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for pdf in pdfs:\n",
    "    data = PyPDFLoader(f\"/content/data/{pdf}\")\n",
    "    docs.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1749a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_from_pdf = docs.load_and_split(text_splitter=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e611f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vstore = AstraDBVectorStore(\n",
    "    embedding=embedding,\n",
    "    collection_name=\"multidoc_vector\",\n",
    "    api_endpoint = ASTRA_DB_API_ENDPOINT,\n",
    "    toke=ASTRA_DB_APPLICATION_TOKEN,\n",
    "    namespace=ASTRA_DB_KEYSPACE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02747e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Documents from PDF : {len(docs_from_pdf)}\")\n",
    "inserted_ids_from_pdf = vstore.add_documents(docs_from_pdf)\n",
    "print(f\"Inserted {len(inserted_ids_from_pdf)} docuemtns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21071834",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vstore.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513217fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"  \n",
    "\n",
    "    You are a philosopher that draws inspiration from great thinkers of the past\n",
    "    to craft well-thought answers to user questions. Use the provided context as the basis\n",
    "    for your answers and do not make up new reasoning paths. just mix-end-match what you are\n",
    "    Your answers must be concise and to the point, and refrain from answering about other top\n",
    "    \n",
    "    CONTEXT:\n",
    "    {context}\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    YOUR_ANSWER:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd9f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "philo_prompt = ChatPromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e27c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\":RunnablePassthrough()}\n",
    "    | philo_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ad7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"How does Russel elaborate on Peirce's idea of the security blanket?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff7e9c",
   "metadata": {},
   "source": [
    "Directory Loaders (Chat With Multiple DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461e9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf \"/content/docs/.ipynb_checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817b8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e90ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt-get install poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e105670",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt-get install libleptonica-dev tesseract-dev tesseract-ocr libtesseract-dev python3-pil tesseract-ocr-eng tesseract-ocr-script-latn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f1987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"/content/docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc693fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter_1 = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcos = loader.load_and_split(text_splitter=splitter_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6963560",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3bd58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inserted_ids = vstore.add_documents(docs)\n",
    "print(f\"\\nInserted {len(inserted_ids)} documetns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_1 = \"\"\"\"\n",
    "\n",
    "    You are an AI philossopher drawing insights from the roadmap of 'rag' , 'llama3', and 'genai'.\n",
    "    Craft thoughtful answers based on this roadmap, mixing and matching existing paths.\n",
    "    Your responses should be soncise and strictly related to the provided context.\n",
    "\n",
    "    ROADMAP CONTEXT:\n",
    "    {context}\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    YOUR ANSWER:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_1 = ChatPromptTemplate.from_template(prompt_template_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1cddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8652bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"Can you tell me the roadmap of Generative AI?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
